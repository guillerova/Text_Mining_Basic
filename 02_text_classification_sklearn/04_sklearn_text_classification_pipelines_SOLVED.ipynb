{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_sklearn_text_classification_pipelines_SOLVED.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "POe5i2WQC8GA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "988f53c6-cd3e-4e80-9ee4-c14458444825"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import __version__ as sklearn_version\n",
        "print('Sklearn version:', sklearn_version)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sklearn version: 0.20.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6oE8GAfvC8GF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The data\n",
        "\n",
        "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date.\n"
      ]
    },
    {
      "metadata": {
        "id": "TD3mk9l_C8GG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
        "\n",
        "twenty_train = fetch_20newsgroups(subset='train',\n",
        "                 remove=('headers', 'footers', 'quotes'),\n",
        "                 categories=categories, shuffle=True, random_state=42)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zq70BkgSC8GI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build a pipeline"
      ]
    },
    {
      "metadata": {
        "id": "6YOFxIh5C8GJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "67163803-f9b0-4d87-8d4f-6c1e8a452f50"
      },
      "cell_type": "code",
      "source": [
        "#Define the pipeline\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english')),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB()),\n",
        "                    ])\n",
        "\n",
        "# Fit all the pipeline\n",
        "text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=0.95, max_features=5000, min_df=2,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
              "       ...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "K6jV6XuxC8GM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00deb573-7fc7-4d65-f3c4-ea8be1f40616"
      },
      "cell_type": "code",
      "source": [
        "#Evaluate test data\n",
        "twenty_test = fetch_20newsgroups(subset='test',\n",
        "                    remove=('headers', 'footers', 'quotes'),\n",
        "                    categories=categories, \n",
        "                    shuffle=True, random_state=42)\n",
        "\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "\n",
        "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.7989347536617842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vI02Sv9_C8GP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Change classifier in the pipeline\n",
        "    - LinearSVC\n",
        "    - k-NN\n",
        "    - Random forest"
      ]
    },
    {
      "metadata": {
        "id": "hZdWz-9vC8GQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb77920e-8d52-40b3-af6a-fd417a0b0477"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english')),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', LinearSVC()),\n",
        "                    ])\n",
        "\n",
        "#Fit\n",
        "_ = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "# Predict\n",
        "predicted = text_clf_svm.predict(twenty_test.data)\n",
        "\n",
        "# Evaluate accuracy\n",
        "print('Test accuracy:', np.mean(predicted == twenty_test.target))        "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8089214380825566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LjlliVD2C8GT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7ff4390-a02c-4455-fd56-3aa2ff68a978"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english')),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', KNeighborsClassifier(n_neighbors=20)),\n",
        "                    ])\n",
        "\n",
        "_ = text_clf.fit(twenty_train.data, twenty_train.target)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.25233022636484687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vdiDV6ItC8GY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9fa4fb6-731d-4f3c-b37e-f1c4fe6d84a1"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=5000, stop_words='english')),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', RandomForestClassifier(n_estimators=100)),\n",
        "                    ])\n",
        "\n",
        "_ = text_clf.fit(twenty_train.data, twenty_train.target)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.7476697736351531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8jF-HctlC8Ga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yTbs_rVC8Gc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use features from a factorization instead the provided by the tf-idf"
      ]
    },
    {
      "metadata": {
        "id": "4KNonaAuC8Gd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c291c431-48b9-4c85-e42e-e230187edbe8"
      },
      "cell_type": "code",
      "source": [
        "# Text preprocessing, tokenizing and filtering of stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
        "                                max_features=5000,\n",
        "                                stop_words='english')\n",
        "X_train_counts = tf_vectorizer.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "4GjVYsQpC8Gg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9a41736c-3bf6-4692-f537-3681875d61d5"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.decomposition import  LatentDirichletAllocation\n",
        "\n",
        "n_components = 6\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=n_components,\n",
        "                                max_iter=5,\n",
        "                                learning_method='online',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0)\n",
        "lda.fit(X_train_counts)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.37 s, sys: 794 µs, total: 3.37 s\n",
            "Wall time: 3.39 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7o_H0X_KC8Gi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a80802e-de32-43bb-c997-7ac144841e04"
      },
      "cell_type": "code",
      "source": [
        "lda.transform(X_train_counts).shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "cS9qSPb8C8Gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "102af2bf-15af-4a14-d20e-748ef4a4dbe9"
      },
      "cell_type": "code",
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(\"Topic #%d:\" % topic_idx)\n",
        "        print(\" \".join([feature_names[i]\n",
        "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
        "    print()\n",
        "\n",
        "n_top_words = 20\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "print_top_words(lda, tf_feature_names, n_top_words)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #0:\n",
            "church pope catholic marriage authority married orthodox canon schism mass liturgy bishop ceremony st churches catholics does priest jurisdiction coptic\n",
            "Topic #1:\n",
            "image file jpeg use program files images gif color know format does thanks graphics software using version bit available like\n",
            "Topic #2:\n",
            "edu com graphics mail send pub keyboard ftp data computer information cs systems software ca faq available gov contact pc\n",
            "Topic #3:\n",
            "god people think don jesus just does believe know say like time bible way things good true life christian question\n",
            "Topic #4:\n",
            "health use medical years people disease food msg new patients like don doctor research time 1993 10 day know just\n",
            "Topic #5:\n",
            "banks gordon skepticism edu soon pitt geb intellect chastity n3jxp dsl shameful cadre surrender father spirit son holy int col\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_lKg7d9ZC8Go",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYZoQYRZC8Gr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pipeline with factorization"
      ]
    },
    {
      "metadata": {
        "id": "U1ym3haYC8Gs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d4f2ecb0-a139-4e3c-d310-3302d4730304"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "text_lda_knn = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=10000, stop_words='english')),\n",
        "                         ('lda', LatentDirichletAllocation(n_components=150, max_iter=15,\n",
        "                                 learning_method='online',\n",
        "                                 learning_offset=200.,\n",
        "                                 random_state=0)),\n",
        "                         ('clf', KNeighborsClassifier(n_neighbors=10))\n",
        "                        ])\n",
        "\n",
        "                         \n",
        "_ = text_lda_knn.fit(twenty_train.data, twenty_train.target)\n",
        "predicted = text_lda_knn.predict(twenty_test.data)\n",
        "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.7003994673768309\n",
            "CPU times: user 1min 30s, sys: 48.4 s, total: 2min 18s\n",
            "Wall time: 1min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0txB9bLyC8Gv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ee1351e5-b307-43f8-e793-01157836faef"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "text_lda_rf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2, max_features=10000, stop_words='english')),\n",
        "                         ('lda', LatentDirichletAllocation(n_components=150, max_iter=15,\n",
        "                                 learning_method='online',\n",
        "                                 learning_offset=200.,\n",
        "                                 random_state=0)),\n",
        "                         ('clf', RandomForestClassifier(n_estimators=100)),\n",
        "                        ])\n",
        "\n",
        "                         \n",
        "_ = text_lda_rf.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "predicted = text_lda_rf.predict(twenty_test.data)\n",
        "print('Test accuracy:', np.mean(predicted == twenty_test.target))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.6864181091877497\n",
            "CPU times: user 1min 32s, sys: 48.5 s, total: 2min 20s\n",
            "Wall time: 1min 15s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DlBpfFFVC8Gy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHsx24QAC8G1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimize a pipeline"
      ]
    },
    {
      "metadata": {
        "id": "WB-G6qwuC8G1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c5194c17-d97f-4ac5-febf-2dcd61baa8a4"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define estimator. No parameters of the search\n",
        "clf = Pipeline([('vect', CountVectorizer(max_df=0.95, min_df=2)),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LinearSVC()),\n",
        "                ])\n",
        "\n",
        "# Specify parameters and distributions to sample from\n",
        "# Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
        "param_dist = {\"vect__max_features\": [1000, 2500, 5000, 7500, 10000, None], \n",
        "              \"vect__stop_words\": ['english', None], \n",
        "              \"clf__C\": [.1, .5, 1., 1.5, 2.]}\n",
        "\n",
        "# Define randomized search\n",
        "n_iter_search = 10\n",
        "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=n_iter_search, return_train_score=True)\n",
        "\n",
        "# Run the randomized search\n",
        "random_search.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "CPU times: user 19.1 s, sys: 53.1 ms, total: 19.1 s\n",
            "Wall time: 19.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A692BUDAC8G5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "f7e74aba-ab46-4c2d-e626-ba4f2b4dd061"
      },
      "cell_type": "code",
      "source": [
        "# Load dictionary of search results to a Pandas dataframe\n",
        "import pandas as pd\n",
        "\n",
        "df_cv_results = pd.DataFrame.from_dict(random_search.cv_results_)\n",
        "df_cv_results"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_vect__stop_words</th>\n",
              "      <th>param_vect__max_features</th>\n",
              "      <th>param_clf__C</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.337459</td>\n",
              "      <td>0.003923</td>\n",
              "      <td>0.110284</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>None</td>\n",
              "      <td>2500</td>\n",
              "      <td>1</td>\n",
              "      <td>{'vect__stop_words': None, 'vect__max_features...</td>\n",
              "      <td>0.828685</td>\n",
              "      <td>0.823373</td>\n",
              "      <td>0.824234</td>\n",
              "      <td>0.825432</td>\n",
              "      <td>0.002329</td>\n",
              "      <td>7</td>\n",
              "      <td>0.981383</td>\n",
              "      <td>0.983378</td>\n",
              "      <td>0.980744</td>\n",
              "      <td>0.981835</td>\n",
              "      <td>0.001122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.273749</td>\n",
              "      <td>0.005288</td>\n",
              "      <td>0.096364</td>\n",
              "      <td>0.006197</td>\n",
              "      <td>english</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
              "      <td>0.841965</td>\n",
              "      <td>0.828685</td>\n",
              "      <td>0.832224</td>\n",
              "      <td>0.834293</td>\n",
              "      <td>0.005617</td>\n",
              "      <td>5</td>\n",
              "      <td>0.978723</td>\n",
              "      <td>0.980718</td>\n",
              "      <td>0.976760</td>\n",
              "      <td>0.978734</td>\n",
              "      <td>0.001616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.319346</td>\n",
              "      <td>0.006841</td>\n",
              "      <td>0.103301</td>\n",
              "      <td>0.005527</td>\n",
              "      <td>english</td>\n",
              "      <td>None</td>\n",
              "      <td>1.5</td>\n",
              "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
              "      <td>0.876494</td>\n",
              "      <td>0.853918</td>\n",
              "      <td>0.868176</td>\n",
              "      <td>0.866194</td>\n",
              "      <td>0.009326</td>\n",
              "      <td>2</td>\n",
              "      <td>0.984043</td>\n",
              "      <td>0.984043</td>\n",
              "      <td>0.982072</td>\n",
              "      <td>0.983386</td>\n",
              "      <td>0.000929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.305115</td>\n",
              "      <td>0.005771</td>\n",
              "      <td>0.109710</td>\n",
              "      <td>0.006599</td>\n",
              "      <td>None</td>\n",
              "      <td>2500</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'vect__stop_words': None, 'vect__max_features...</td>\n",
              "      <td>0.833997</td>\n",
              "      <td>0.800797</td>\n",
              "      <td>0.813582</td>\n",
              "      <td>0.816128</td>\n",
              "      <td>0.013679</td>\n",
              "      <td>9</td>\n",
              "      <td>0.932846</td>\n",
              "      <td>0.931516</td>\n",
              "      <td>0.934263</td>\n",
              "      <td>0.932875</td>\n",
              "      <td>0.001122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.333399</td>\n",
              "      <td>0.004365</td>\n",
              "      <td>0.102019</td>\n",
              "      <td>0.005683</td>\n",
              "      <td>english</td>\n",
              "      <td>7500</td>\n",
              "      <td>2</td>\n",
              "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
              "      <td>0.871182</td>\n",
              "      <td>0.852590</td>\n",
              "      <td>0.858855</td>\n",
              "      <td>0.860877</td>\n",
              "      <td>0.007727</td>\n",
              "      <td>4</td>\n",
              "      <td>0.984043</td>\n",
              "      <td>0.984043</td>\n",
              "      <td>0.982072</td>\n",
              "      <td>0.983386</td>\n",
              "      <td>0.000929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.309382</td>\n",
              "      <td>0.007715</td>\n",
              "      <td>0.105013</td>\n",
              "      <td>0.008684</td>\n",
              "      <td>english</td>\n",
              "      <td>7500</td>\n",
              "      <td>1</td>\n",
              "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
              "      <td>0.879150</td>\n",
              "      <td>0.855246</td>\n",
              "      <td>0.865513</td>\n",
              "      <td>0.866637</td>\n",
              "      <td>0.009795</td>\n",
              "      <td>1</td>\n",
              "      <td>0.983378</td>\n",
              "      <td>0.984043</td>\n",
              "      <td>0.981408</td>\n",
              "      <td>0.982943</td>\n",
              "      <td>0.001119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.339095</td>\n",
              "      <td>0.003503</td>\n",
              "      <td>0.105586</td>\n",
              "      <td>0.003889</td>\n",
              "      <td>english</td>\n",
              "      <td>10000</td>\n",
              "      <td>2</td>\n",
              "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
              "      <td>0.873838</td>\n",
              "      <td>0.852590</td>\n",
              "      <td>0.868176</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>3</td>\n",
              "      <td>0.984707</td>\n",
              "      <td>0.984043</td>\n",
              "      <td>0.982072</td>\n",
              "      <td>0.983607</td>\n",
              "      <td>0.001119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.267068</td>\n",
              "      <td>0.002429</td>\n",
              "      <td>0.094573</td>\n",
              "      <td>0.006572</td>\n",
              "      <td>english</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
              "      <td>0.818061</td>\n",
              "      <td>0.806109</td>\n",
              "      <td>0.802929</td>\n",
              "      <td>0.809039</td>\n",
              "      <td>0.006515</td>\n",
              "      <td>10</td>\n",
              "      <td>0.916888</td>\n",
              "      <td>0.919548</td>\n",
              "      <td>0.916999</td>\n",
              "      <td>0.917812</td>\n",
              "      <td>0.001229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.315408</td>\n",
              "      <td>0.005662</td>\n",
              "      <td>0.115294</td>\n",
              "      <td>0.007816</td>\n",
              "      <td>None</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'vect__stop_words': None, 'vect__max_features...</td>\n",
              "      <td>0.843293</td>\n",
              "      <td>0.818061</td>\n",
              "      <td>0.825566</td>\n",
              "      <td>0.828977</td>\n",
              "      <td>0.010583</td>\n",
              "      <td>6</td>\n",
              "      <td>0.954122</td>\n",
              "      <td>0.950798</td>\n",
              "      <td>0.947543</td>\n",
              "      <td>0.950821</td>\n",
              "      <td>0.002686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.295355</td>\n",
              "      <td>0.005530</td>\n",
              "      <td>0.096506</td>\n",
              "      <td>0.004703</td>\n",
              "      <td>english</td>\n",
              "      <td>2500</td>\n",
              "      <td>1.5</td>\n",
              "      <td>{'vect__stop_words': 'english', 'vect__max_fea...</td>\n",
              "      <td>0.827357</td>\n",
              "      <td>0.815405</td>\n",
              "      <td>0.822903</td>\n",
              "      <td>0.821887</td>\n",
              "      <td>0.004934</td>\n",
              "      <td>8</td>\n",
              "      <td>0.982713</td>\n",
              "      <td>0.982713</td>\n",
              "      <td>0.981408</td>\n",
              "      <td>0.982278</td>\n",
              "      <td>0.000615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0       0.337459      0.003923         0.110284        0.006579   \n",
              "1       0.273749      0.005288         0.096364        0.006197   \n",
              "2       0.319346      0.006841         0.103301        0.005527   \n",
              "3       0.305115      0.005771         0.109710        0.006599   \n",
              "4       0.333399      0.004365         0.102019        0.005683   \n",
              "5       0.309382      0.007715         0.105013        0.008684   \n",
              "6       0.339095      0.003503         0.105586        0.003889   \n",
              "7       0.267068      0.002429         0.094573        0.006572   \n",
              "8       0.315408      0.005662         0.115294        0.007816   \n",
              "9       0.295355      0.005530         0.096506        0.004703   \n",
              "\n",
              "  param_vect__stop_words param_vect__max_features param_clf__C  \\\n",
              "0                   None                     2500            1   \n",
              "1                english                     2500          0.5   \n",
              "2                english                     None          1.5   \n",
              "3                   None                     2500          0.1   \n",
              "4                english                     7500            2   \n",
              "5                english                     7500            1   \n",
              "6                english                    10000            2   \n",
              "7                english                     1000          0.1   \n",
              "8                   None                    10000          0.1   \n",
              "9                english                     2500          1.5   \n",
              "\n",
              "                                              params  split0_test_score  \\\n",
              "0  {'vect__stop_words': None, 'vect__max_features...           0.828685   \n",
              "1  {'vect__stop_words': 'english', 'vect__max_fea...           0.841965   \n",
              "2  {'vect__stop_words': 'english', 'vect__max_fea...           0.876494   \n",
              "3  {'vect__stop_words': None, 'vect__max_features...           0.833997   \n",
              "4  {'vect__stop_words': 'english', 'vect__max_fea...           0.871182   \n",
              "5  {'vect__stop_words': 'english', 'vect__max_fea...           0.879150   \n",
              "6  {'vect__stop_words': 'english', 'vect__max_fea...           0.873838   \n",
              "7  {'vect__stop_words': 'english', 'vect__max_fea...           0.818061   \n",
              "8  {'vect__stop_words': None, 'vect__max_features...           0.843293   \n",
              "9  {'vect__stop_words': 'english', 'vect__max_fea...           0.827357   \n",
              "\n",
              "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "0           0.823373           0.824234         0.825432        0.002329   \n",
              "1           0.828685           0.832224         0.834293        0.005617   \n",
              "2           0.853918           0.868176         0.866194        0.009326   \n",
              "3           0.800797           0.813582         0.816128        0.013679   \n",
              "4           0.852590           0.858855         0.860877        0.007727   \n",
              "5           0.855246           0.865513         0.866637        0.009795   \n",
              "6           0.852590           0.868176         0.864865        0.008988   \n",
              "7           0.806109           0.802929         0.809039        0.006515   \n",
              "8           0.818061           0.825566         0.828977        0.010583   \n",
              "9           0.815405           0.822903         0.821887        0.004934   \n",
              "\n",
              "   rank_test_score  split0_train_score  split1_train_score  \\\n",
              "0                7            0.981383            0.983378   \n",
              "1                5            0.978723            0.980718   \n",
              "2                2            0.984043            0.984043   \n",
              "3                9            0.932846            0.931516   \n",
              "4                4            0.984043            0.984043   \n",
              "5                1            0.983378            0.984043   \n",
              "6                3            0.984707            0.984043   \n",
              "7               10            0.916888            0.919548   \n",
              "8                6            0.954122            0.950798   \n",
              "9                8            0.982713            0.982713   \n",
              "\n",
              "   split2_train_score  mean_train_score  std_train_score  \n",
              "0            0.980744          0.981835         0.001122  \n",
              "1            0.976760          0.978734         0.001616  \n",
              "2            0.982072          0.983386         0.000929  \n",
              "3            0.934263          0.932875         0.001122  \n",
              "4            0.982072          0.983386         0.000929  \n",
              "5            0.981408          0.982943         0.001119  \n",
              "6            0.982072          0.983607         0.001119  \n",
              "7            0.916999          0.917812         0.001229  \n",
              "8            0.947543          0.950821         0.002686  \n",
              "9            0.981408          0.982278         0.000615  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "S3kuqDe8C8G8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c1046e3-0976-44c7-edb3-aa70583adfca"
      },
      "cell_type": "code",
      "source": [
        "print('Best params:', random_search.best_params_)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params: {'vect__stop_words': 'english', 'vect__max_features': 7500, 'clf__C': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OOjUQE4GC8HA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f3bce15-7e7f-4428-a314-5288e0e722ee"
      },
      "cell_type": "code",
      "source": [
        "# Score & evaluate test data using the best estimator\n",
        "\n",
        "predicted = random_search.best_estimator_.predict(twenty_test.data)\n",
        "\n",
        "print('Test accuracy:', np.mean(predicted == twenty_test.target))        "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8202396804260985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xr5dyXhhC8HD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KkKYi4qvC8HE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Aditional metrics for multiclass classification"
      ]
    },
    {
      "metadata": {
        "id": "T-f1v5_NC8HF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "0e17f13c-80b9-4b52-ac7b-0484a5655f76"
      },
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(twenty_test.target, \n",
        "                                    predicted,\n",
        "                                    target_names=twenty_test.target_names))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.77      0.63      0.69       319\n",
            "         comp.graphics       0.82      0.92      0.87       389\n",
            "               sci.med       0.88      0.85      0.87       396\n",
            "soc.religion.christian       0.80      0.84      0.82       398\n",
            "\n",
            "             micro avg       0.82      0.82      0.82      1502\n",
            "             macro avg       0.82      0.81      0.81      1502\n",
            "          weighted avg       0.82      0.82      0.82      1502\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RApjmR4WC8HH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0b8cc99b-796b-4520-a169-81fad292f830"
      },
      "cell_type": "code",
      "source": [
        "metrics.confusion_matrix(twenty_test.target, predicted)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[200,  22,  24,  73],\n",
              "       [ 15, 359,  15,   0],\n",
              "       [ 14,  32, 337,  13],\n",
              "       [ 32,  23,   7, 336]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "ZeR4njW3C8HN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}